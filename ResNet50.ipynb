{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rdesarz/zoo/blob/main/ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4QaDSsjMVBEO",
    "outputId": "485052b3-2924-4c49-b8df-05cfe24e72d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check for Tensorflow version\n",
    "print(tf.__version__)\n",
    "\n",
    "# Check if there is an existing GPU device\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DrhMC00iVgQY"
   },
   "outputs": [],
   "source": [
    "# We use the CIFAR-10 datasets for this example\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7Yk-CSTFXCkK"
   },
   "outputs": [],
   "source": [
    "CLASS_NAMES= ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "DPBaRQUsXD6F",
    "outputId": "5ccf6b5f-d5f8-46e7-c5ca-db03d1ae27dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f01f81d57c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_index = np.random.randint(low=0, high = train_images.shape[0])\n",
    "plt.imshow(train_images[image_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NB7wXtIaXFKf"
   },
   "outputs": [],
   "source": [
    "# Processing function\n",
    "def process_image(image, label, shuffle=False, augment=False):\n",
    "  image=tf.image.per_image_standardization(image)\n",
    "  image=tf.image.resize(image,(64,64))\n",
    "\n",
    "  return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "oaoxkYKHXLMF"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "\n",
    "train_ds_size = tf.data.experimental.cardinality(train_dataset).numpy()\n",
    "test_ds_size = tf.data.experimental.cardinality(test_dataset).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8jTQ9g-SXNIJ"
   },
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset=(train_dataset\n",
    "          .map(process_image)\n",
    "          .map(lambda x, y: (data_augmentation(x, training=True), y), \n",
    "                num_parallel_calls=tf.data.AUTOTUNE)\n",
    "          .shuffle(buffer_size=train_ds_size)\n",
    "          .batch(batch_size=64,drop_remainder=True))\n",
    "test_dataset=(test_dataset\n",
    "          .map(process_image)\n",
    "          .shuffle(buffer_size=test_ds_size)\n",
    "          .batch(batch_size=64,drop_remainder=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YP8IJYRpXPT8"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, BatchNormalization, Activation, Add\n",
    "\n",
    "def conv2(x, downsample=False, conv_skip=False):\n",
    "    \"\"\"\n",
    "    Residual block\n",
    "    \"\"\"\n",
    "    # Create skip connection\n",
    "    x_skip = x  \n",
    "    \n",
    "    first_layer_strides = (2, 2) if downsample else (1, 1)\n",
    "\n",
    "    # Perform the original mapping\n",
    "    x = Conv2D(64, kernel_size=(1, 1), strides=first_layer_strides, padding=\"valid\")(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(64, kernel_size=(3, 3), strides=(1,1), padding=\"same\")(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(256, kernel_size=(1, 1), strides=(1,1), padding=\"valid\")(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "\n",
    "    if conv_skip:\n",
    "        x_skip = Conv2D(filters=256, kernel_size=(1, 1), strides=first_layer_strides,\n",
    "                        padding=\"same\")(x_skip)\n",
    "        x_skip = BatchNormalization(axis=3)(x_skip)\n",
    "\n",
    "    # Add the skip connection to the regular mapping\n",
    "    x = Add()([x, x_skip])\n",
    "\n",
    "    # Nonlinearly activate the result\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    # Return the result\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv3(x, downsample=False, conv_skip=False):\n",
    "    \"\"\"\n",
    "    Residual block\n",
    "    \"\"\"\n",
    "    # Create skip connection\n",
    "    x_skip = x  \n",
    "\n",
    "    first_layer_strides = (2, 2) if downsample else (1, 1)\n",
    "    \n",
    "    # Perform the original mapping\n",
    "    x = Conv2D(128, kernel_size=(1, 1), strides=first_layer_strides, padding=\"valid\")(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(128, kernel_size=(3, 3), strides=(1,1), padding=\"same\")(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(512, kernel_size=(1, 1), strides=(1,1), padding=\"valid\")(x)\n",
    "    x = BatchNormalization(axis=3)(x) \n",
    "\n",
    "    if conv_skip:\n",
    "        x_skip = Conv2D(filters=512, kernel_size=(1, 1), strides=first_layer_strides,\n",
    "                        padding=\"same\")(x_skip)\n",
    "        x_skip = BatchNormalization(axis=3)(x_skip)\n",
    "\n",
    "    # Add the skip connection to the regular mapping\n",
    "    x = Add()([x, x_skip])\n",
    "\n",
    "    # Nonlinearly activate the result\n",
    "    x = Activation(\"relu\")(x)  \n",
    "\n",
    "    # Return the result\n",
    "    return x\n",
    "\n",
    "def conv4(x, downsample=False, conv_skip=False):\n",
    "    \"\"\"\n",
    "    Residual block\n",
    "    \"\"\"\n",
    "    # Create skip connection\n",
    "    x_skip = x  \n",
    "\n",
    "    first_layer_strides = (2, 2) if downsample else (1, 1)\n",
    "    \n",
    "    # Perform the original mapping\n",
    "    x = Conv2D(256, kernel_size=(1, 1), strides=first_layer_strides, padding=\"valid\")(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(256, kernel_size=(3, 3), strides=(1,1), padding=\"same\")(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(1024, kernel_size=(1, 1), strides=(1,1), padding=\"valid\")(x)\n",
    "    x = BatchNormalization(axis=3)(x) \n",
    "\n",
    "    if conv_skip:\n",
    "        x_skip = Conv2D(filters=1024, kernel_size=(1, 1), strides=first_layer_strides,\n",
    "                        padding=\"same\")(x_skip)\n",
    "        x_skip = BatchNormalization(axis=3)(x_skip)\n",
    "\n",
    "    # Add the skip connection to the regular mapping\n",
    "    x = Add()([x, x_skip])\n",
    "\n",
    "    # Nonlinearly activate the result\n",
    "    x = Activation(\"relu\")(x)  \n",
    "\n",
    "    # Return the result\n",
    "    return x\n",
    "\n",
    "def conv5(x, downsample=False, conv_skip=False):\n",
    "    \"\"\"\n",
    "    Residual block\n",
    "    \"\"\"\n",
    "    # Create skip connection\n",
    "    x_skip = x  \n",
    "\n",
    "    first_layer_strides = (2, 2) if downsample else (1, 1)\n",
    "    \n",
    "    # Perform the original mapping\n",
    "    x = Conv2D(512, kernel_size=(1, 1), strides=first_layer_strides, padding=\"valid\")(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(512, kernel_size=(3, 3), strides=(1,1), padding=\"same\")(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(2048, kernel_size=(1, 1), strides=(1,1), padding=\"valid\")(x)\n",
    "    x = BatchNormalization(axis=3)(x) \n",
    "\n",
    "\n",
    "    if conv_skip:\n",
    "       x_skip = Conv2D(filters=2048, kernel_size=(1, 1), strides=first_layer_strides,\n",
    "                       padding=\"same\")(x_skip)\n",
    "       x_skip = BatchNormalization(axis=3)(x_skip)\n",
    "\n",
    "    # Add the skip connection to the regular mapping\n",
    "    x = Add()([x, x_skip])\n",
    "\n",
    "    # Nonlinearly activate the result\n",
    "    x = Activation(\"relu\")(x)  \n",
    "\n",
    "    # Return the result\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "thl3qNPhcOj9"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dense\n",
    "\n",
    "def model_base():\n",
    "    # Define model structure\n",
    "    # logits are returned because Softmax is pushed to loss function.\n",
    "    inputs = Input(shape=(64, 64, 3))\n",
    "    x = Conv2D(64, kernel_size=(7,7),\tstrides=(2,2), padding=\"same\")(inputs)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    # First residual blocks\n",
    "    x = conv2(x, conv_skip=True)\n",
    "    x = conv2(x)\n",
    "    x = conv2(x)\n",
    "\n",
    "    # Second residual blocks\n",
    "    x = conv3(x, downsample=True, conv_skip=True)\n",
    "    x = conv3(x)\n",
    "    x = conv3(x)\n",
    "    x = conv3(x)\n",
    "\n",
    "    # Third residual blocks\n",
    "    x = conv4(x, downsample=True, conv_skip=True)\n",
    "    x = conv4(x)\n",
    "    x = conv4(x)\n",
    "    x = conv4(x)\n",
    "    x = conv4(x)\n",
    "    x = conv4(x)\n",
    "\n",
    "    # Fourth residual blocks\n",
    "    x = conv5(x, downsample=True, conv_skip=True)\n",
    "    x = conv5(x)\n",
    "    x = conv5(x)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PNdYVQXokW_P",
    "outputId": "24b989b7-d4a6-4a19-ff0f-dcb35013b60c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 64)   9472        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 15, 15, 64)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 15, 15, 64)  256         ['max_pooling2d[0][0]']          \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 15, 15, 64)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 15, 15, 64)   4160        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 15, 15, 64)  256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 15, 15, 64)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 15, 15, 64)   36928       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 15, 15, 64)  256         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 15, 15, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 15, 15, 256)  16640       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 15, 15, 256)  16640       ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 15, 15, 256)  1024       ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 15, 15, 256)  1024       ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 15, 15, 256)  0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 15, 15, 256)  0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 15, 15, 64)   16448       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 15, 15, 64)  256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 15, 15, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 15, 15, 64)   36928       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 15, 15, 64)  256         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 15, 15, 64)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 15, 15, 256)  16640       ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 15, 15, 256)  1024       ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 15, 15, 256)  0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 15, 15, 256)  0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 15, 15, 64)   16448       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 15, 15, 64)  256         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 15, 15, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 15, 15, 64)   36928       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 15, 15, 64)  256         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 15, 15, 64)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 15, 15, 256)  16640       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 15, 15, 256)  0           ['batch_normalization_10[0][0]', \n",
      "                                                                  'activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 15, 15, 256)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 8, 8, 128)    32896       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 8, 8, 128)   512         ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 8, 8, 128)   512         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 8, 8, 512)    131584      ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 8, 8, 512)    0           ['batch_normalization_13[0][0]', \n",
      "                                                                  'batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 8, 8, 512)    0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 8, 8, 128)   512         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 8, 8, 128)   512         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 8, 8, 512)    0           ['batch_normalization_17[0][0]', \n",
      "                                                                  'activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 8, 8, 512)    0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 8, 8, 128)   512         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 8, 8, 128)   512         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 8, 8, 512)    0           ['batch_normalization_20[0][0]', \n",
      "                                                                  'activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 8, 8, 512)    0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 8, 8, 128)   512         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 8, 8, 128)   512         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 8, 8, 512)    0           ['batch_normalization_23[0][0]', \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 8, 8, 512)    0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 4, 4, 256)    131328      ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 4, 4, 1024)   525312      ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 4, 4, 1024)   0           ['batch_normalization_26[0][0]', \n",
      "                                                                  'batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 4, 4, 1024)   0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 4, 4, 1024)   0           ['batch_normalization_30[0][0]', \n",
      "                                                                  'activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 4, 4, 1024)   0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 4, 4, 1024)   0           ['batch_normalization_33[0][0]', \n",
      "                                                                  'activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 4, 4, 1024)   0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 4, 4, 1024)   0           ['batch_normalization_36[0][0]', \n",
      "                                                                  'activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 4, 4, 1024)   0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 4, 4, 1024)   0           ['batch_normalization_39[0][0]', \n",
      "                                                                  'activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 4, 4, 1024)   0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 4, 4, 1024)   0           ['batch_normalization_42[0][0]', \n",
      "                                                                  'activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 4, 4, 1024)   0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 2, 2, 512)    524800      ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 2, 2, 2048)   2099200     ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 2, 2, 2048)   0           ['batch_normalization_45[0][0]', \n",
      "                                                                  'batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 2, 2, 2048)   0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 2, 2, 512)    1049088     ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 2, 2, 2048)   0           ['batch_normalization_49[0][0]', \n",
      "                                                                  'activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 2, 2, 2048)   0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 2, 2, 512)    1049088     ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 2, 2, 2048)   0           ['batch_normalization_52[0][0]', \n",
      "                                                                  'activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 2, 2, 2048)   0           ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['activation_48[0][0]']          \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 10)           20490       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,608,202\n",
      "Trainable params: 23,555,082\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get model base\n",
    "inputs, outputs = model_base()\n",
    "\n",
    "# Initialize and compile model\n",
    "model = tf.keras.Model(inputs, outputs, name=\"ResNet50\")\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.optimizers.SGD(learning_rate=0.1, momentum=0.9),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9q7kFmMqDQ9",
    "outputId": "c91e781b-9721-48c6-cd85-2e5a01708264"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "781/781 [==============================] - 53s 57ms/step - loss: 2.7037 - accuracy: 0.2087 - val_loss: 1.9656 - val_accuracy: 0.2699 - lr: 0.1000\n",
      "Epoch 2/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 1.7854 - accuracy: 0.3396 - val_loss: 1.7545 - val_accuracy: 0.3945 - lr: 0.1000\n",
      "Epoch 3/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 1.6089 - accuracy: 0.4190 - val_loss: 1.5523 - val_accuracy: 0.4542 - lr: 0.1000\n",
      "Epoch 4/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 1.4894 - accuracy: 0.4625 - val_loss: 1.5064 - val_accuracy: 0.4742 - lr: 0.1000\n",
      "Epoch 5/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 1.3763 - accuracy: 0.5055 - val_loss: 1.4438 - val_accuracy: 0.4921 - lr: 0.1000\n",
      "Epoch 6/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 1.2824 - accuracy: 0.5423 - val_loss: 1.2773 - val_accuracy: 0.5453 - lr: 0.1000\n",
      "Epoch 7/100\n",
      "781/781 [==============================] - 49s 57ms/step - loss: 1.2057 - accuracy: 0.5685 - val_loss: 1.2413 - val_accuracy: 0.5595 - lr: 0.1000\n",
      "Epoch 8/100\n",
      "781/781 [==============================] - 49s 57ms/step - loss: 1.1354 - accuracy: 0.5970 - val_loss: 1.5843 - val_accuracy: 0.5430 - lr: 0.1000\n",
      "Epoch 9/100\n",
      "781/781 [==============================] - 49s 56ms/step - loss: 1.0773 - accuracy: 0.6183 - val_loss: 1.1476 - val_accuracy: 0.5974 - lr: 0.1000\n",
      "Epoch 10/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 1.0244 - accuracy: 0.6369 - val_loss: 1.6100 - val_accuracy: 0.6151 - lr: 0.1000\n",
      "Epoch 11/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 0.9791 - accuracy: 0.6524 - val_loss: 2.0203 - val_accuracy: 0.6181 - lr: 0.1000\n",
      "Epoch 12/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 0.9319 - accuracy: 0.6688 - val_loss: 1.2500 - val_accuracy: 0.6416 - lr: 0.1000\n",
      "Epoch 13/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 0.8914 - accuracy: 0.6841 - val_loss: 1.3153 - val_accuracy: 0.6453 - lr: 0.1000\n",
      "Epoch 14/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 0.8539 - accuracy: 0.6982 - val_loss: 1.3579 - val_accuracy: 0.6560 - lr: 0.1000\n",
      "Epoch 15/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 0.7210 - accuracy: 0.7446 - val_loss: 1.0128 - val_accuracy: 0.6966 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 0.6721 - accuracy: 0.7645 - val_loss: 1.0632 - val_accuracy: 0.6989 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 0.6502 - accuracy: 0.7713 - val_loss: 1.0652 - val_accuracy: 0.7045 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 0.6268 - accuracy: 0.7794 - val_loss: 1.0459 - val_accuracy: 0.7064 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 0.6110 - accuracy: 0.7861 - val_loss: 1.2235 - val_accuracy: 0.7052 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 0.5923 - accuracy: 0.7925 - val_loss: 1.3237 - val_accuracy: 0.7096 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 0.5661 - accuracy: 0.8021 - val_loss: 1.6454 - val_accuracy: 0.7096 - lr: 1.0000e-03\n",
      "Epoch 22/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 0.5630 - accuracy: 0.8048 - val_loss: 1.6450 - val_accuracy: 0.7087 - lr: 1.0000e-03\n",
      "Epoch 23/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 0.5567 - accuracy: 0.8034 - val_loss: 1.4682 - val_accuracy: 0.7107 - lr: 1.0000e-03\n",
      "Epoch 24/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 0.5519 - accuracy: 0.8100 - val_loss: 1.6262 - val_accuracy: 0.7096 - lr: 1.0000e-03\n",
      "Epoch 25/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 0.5500 - accuracy: 0.8083 - val_loss: 1.5251 - val_accuracy: 0.7113 - lr: 1.0000e-03\n",
      "Epoch 26/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 0.5478 - accuracy: 0.8099 - val_loss: 1.6039 - val_accuracy: 0.7098 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 0.5446 - accuracy: 0.8118 - val_loss: 1.5680 - val_accuracy: 0.7110 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 0.5453 - accuracy: 0.8103 - val_loss: 1.7519 - val_accuracy: 0.7112 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 0.5436 - accuracy: 0.8094 - val_loss: 1.6656 - val_accuracy: 0.7112 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "781/781 [==============================] - 48s 55ms/step - loss: 0.5467 - accuracy: 0.8100 - val_loss: 1.7410 - val_accuracy: 0.7106 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "781/781 [==============================] - 48s 56ms/step - loss: 0.5461 - accuracy: 0.8103 - val_loss: 1.8698 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "781/781 [==============================] - 47s 55ms/step - loss: 0.5488 - accuracy: 0.8099 - val_loss: 1.7158 - val_accuracy: 0.7106 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "781/781 [==============================] - 47s 54ms/step - loss: 0.5463 - accuracy: 0.8101 - val_loss: 1.5002 - val_accuracy: 0.7128 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "781/781 [==============================] - 47s 54ms/step - loss: 0.5436 - accuracy: 0.8105 - val_loss: 1.8655 - val_accuracy: 0.7107 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "781/781 [==============================] - 47s 54ms/step - loss: 0.5449 - accuracy: 0.8100 - val_loss: 1.6959 - val_accuracy: 0.7125 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "781/781 [==============================] - 47s 54ms/step - loss: 0.5427 - accuracy: 0.8113 - val_loss: 1.6863 - val_accuracy: 0.7123 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "781/781 [==============================] - 47s 54ms/step - loss: 0.5427 - accuracy: 0.8105 - val_loss: 1.7745 - val_accuracy: 0.7112 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "781/781 [==============================] - 47s 54ms/step - loss: 0.5454 - accuracy: 0.8101 - val_loss: 1.5526 - val_accuracy: 0.7112 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "781/781 [==============================] - 47s 54ms/step - loss: 0.5409 - accuracy: 0.8115 - val_loss: 1.8742 - val_accuracy: 0.7106 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "781/781 [==============================] - 47s 54ms/step - loss: 0.5435 - accuracy: 0.8102 - val_loss: 1.7031 - val_accuracy: 0.7127 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "781/781 [==============================] - 47s 54ms/step - loss: 0.5422 - accuracy: 0.8127 - val_loss: 1.7066 - val_accuracy: 0.7118 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "781/781 [==============================] - 47s 54ms/step - loss: 0.5423 - accuracy: 0.8103 - val_loss: 1.7983 - val_accuracy: 0.7112 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "781/781 [==============================] - 47s 54ms/step - loss: 0.5386 - accuracy: 0.8127 - val_loss: 1.7548 - val_accuracy: 0.7113 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "781/781 [==============================] - 47s 54ms/step - loss: 0.5429 - accuracy: 0.8115 - val_loss: 1.6195 - val_accuracy: 0.7109 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "781/781 [==============================] - 47s 54ms/step - loss: 0.5390 - accuracy: 0.8127 - val_loss: 1.5609 - val_accuracy: 0.7127 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "781/781 [==============================] - 49s 56ms/step - loss: 0.5382 - accuracy: 0.8112 - val_loss: 1.6965 - val_accuracy: 0.7117 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "781/781 [==============================] - 49s 57ms/step - loss: 0.5385 - accuracy: 0.8138 - val_loss: 1.5508 - val_accuracy: 0.7121 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "674/781 [========================>.....] - ETA: 5s - loss: 0.5402 - accuracy: 0.8114"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m      2\u001b[0m                               patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m history\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1389\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1388\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1389\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1391\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 438\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 297\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    300\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    316\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    321\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    355\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 356\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    359\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1034\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1105\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1106\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py:563\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py:557\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    555\u001b[0m   \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 557\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m   \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:1223\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1223\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:1189\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1188\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1190\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=5, min_lr=0.0001)\n",
    "\n",
    "history=model.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,\n",
    "    validation_data=test_dataset,\n",
    "    validation_freq=1,\n",
    "    callbacks=[reduce_lr]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM0mXzHOWq+F8l+p8kvYgrs",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ResNet50.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
